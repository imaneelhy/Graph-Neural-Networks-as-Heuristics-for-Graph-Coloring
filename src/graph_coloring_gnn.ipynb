{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76XKZu8JgEND"
      },
      "outputs": [],
      "source": [
        "!pip install networkx matplotlib tqdm --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rw1tQSiaEmpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rqyVBF_kEmiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mBKH5fHTmg24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQTugiVYmg_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iuAssL-umhCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pBxzVs5FmhJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vLsOQjGNmhLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Graph Coloring with GNN Guidance – \"Best Results\" Version\n",
        "# ============================================================\n",
        "\n",
        "import random\n",
        "import time\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Global config & reproducibility\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# ===================== USER-CONFIGURABLE =====================\n",
        "\n",
        "# Model type: \"gcn\", \"resgcn\" (default, strongest), or \"mlp\" baseline\n",
        "MODEL_TYPE = \"resgcn\"\n",
        "\n",
        "# Whether to canonicalize colors per graph\n",
        "# Keep this False so labels stay consistent across graphs.\n",
        "USE_CANONICAL_COLORS = False\n",
        "\n",
        "# Difficulty regimes\n",
        "REGIMES = {\n",
        "    \"easy\": {\n",
        "        \"n_range\": (10, 18),\n",
        "        \"p_range\": (0.20, 0.45),\n",
        "        \"hard_min\": 5,\n",
        "        \"hard_max\": 150,\n",
        "    },\n",
        "    \"medium\": {\n",
        "        \"n_range\": (18, 30),\n",
        "        \"p_range\": (0.15, 0.40),\n",
        "        \"hard_min\": 20,\n",
        "        \"hard_max\": 1000,\n",
        "    },\n",
        "    \"hard\": {\n",
        "        \"n_range\": (25, 45),\n",
        "        \"p_range\": (0.15, 0.35),\n",
        "        \"hard_min\": 50,\n",
        "        \"hard_max\": 5000,\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick which regime to run\n",
        "# For strongest “working” result, start with \"easy\".\n",
        "REGIME = \"easy\"   # change to \"medium\" or \"hard\" for extra experiments\n",
        "\n",
        "# Graph coloring / dataset config\n",
        "K_COLORS = 4                 # number of colors solver must use\n",
        "\n",
        "# Target number of graphs\n",
        "NUM_TRAIN = 1000\n",
        "NUM_VAL   = 200\n",
        "NUM_TEST  = 200\n",
        "NUM_TOTAL = NUM_TRAIN + NUM_VAL + NUM_TEST\n",
        "\n",
        "MAX_LABEL_BACKTRACKS = 20000  # safety limit when generating labels\n",
        "\n",
        "# Node features: degree, normalized degree, clustering, 2-hop degree norm\n",
        "NODE_FEATURE_DIM = 4\n",
        "\n",
        "# GNN training config\n",
        "HIDDEN_DIM   = 256     # bigger model\n",
        "NUM_LAYERS   = 6       # used by plain GCN; ResGCN has its own depth\n",
        "LR           = 3e-3\n",
        "WEIGHT_DECAY = 5e-5\n",
        "EPOCHS       = 200\n",
        "PATIENCE     = 30\n",
        "\n",
        "# Violation loss: OFF by default for clean CE training,\n",
        "# but you can turn this ON for ablations (especially on harder regimes).\n",
        "USE_VIOLATION_LOSS = False\n",
        "LAMBDA_VIOL        = 0.1\n",
        "\n",
        "# Optional debug flag: overfit a single graph after dataset generation\n",
        "RUN_SINGLE_GRAPH_DEBUG = False\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 1. Classical backtracking solver\n",
        "# ============================================================\n",
        "\n",
        "def solve_graph_coloring(adj, k,\n",
        "                         node_order=None,\n",
        "                         init_colors=None,\n",
        "                         color_order=None,\n",
        "                         max_backtracks=None):\n",
        "    \"\"\"\n",
        "    Simple backtracking graph coloring solver.\n",
        "    - adj: numpy [N, N] 0/1\n",
        "    - k: number of colors\n",
        "    - node_order: list of node indices (variable ordering)\n",
        "    - init_colors: optional array [N] of 'preferred' colors (-1 if none)\n",
        "      (used only when color_order is None)\n",
        "    - color_order: optional array [N, k] where color_order[v] is a\n",
        "      permutation of [0..k-1] giving the order to try colors at node v.\n",
        "    - max_backtracks: limit search effort\n",
        "    Returns: (success: bool, assignment: np.ndarray[N], stats: dict)\n",
        "    \"\"\"\n",
        "    adj = np.array(adj, dtype=np.float32)\n",
        "    n = adj.shape[0]\n",
        "    neighbors = [np.where(adj[v] > 0.5)[0] for v in range(n)]\n",
        "\n",
        "    if node_order is None:\n",
        "        node_order = list(range(n))\n",
        "    else:\n",
        "        node_order = list(node_order)\n",
        "\n",
        "    assignment = np.full(n, -1, dtype=np.int64)\n",
        "    if init_colors is not None:\n",
        "        init_colors = np.array(init_colors, dtype=np.int64)\n",
        "    backtracks = 0\n",
        "    steps = 0\n",
        "\n",
        "    def is_consistent(v, c):\n",
        "        for u in neighbors[v]:\n",
        "            if assignment[u] == c:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def backtrack(pos):\n",
        "        nonlocal backtracks, steps\n",
        "        if pos == len(node_order):\n",
        "            return True\n",
        "\n",
        "        v = node_order[pos]\n",
        "\n",
        "        # If a per-node color order is provided, use it.\n",
        "        if color_order is not None:\n",
        "            colors_to_try = list(color_order[v])\n",
        "        else:\n",
        "            # Default: 0..k-1, with optional preferred color first\n",
        "            colors_to_try = list(range(k))\n",
        "            if init_colors is not None and init_colors[v] != -1:\n",
        "                preferred = int(init_colors[v])\n",
        "                if preferred in colors_to_try:\n",
        "                    colors_to_try.remove(preferred)\n",
        "                    colors_to_try = [preferred] + colors_to_try\n",
        "\n",
        "        for c in colors_to_try:\n",
        "            steps += 1\n",
        "            if is_consistent(v, c):\n",
        "                assignment[v] = c\n",
        "                if backtrack(pos + 1):\n",
        "                    return True\n",
        "                assignment[v] = -1\n",
        "                backtracks += 1\n",
        "                if max_backtracks is not None and backtracks >= max_backtracks:\n",
        "                    return False\n",
        "        return False\n",
        "\n",
        "    success = backtrack(0)\n",
        "    stats = {\"backtracks\": backtracks, \"steps\": steps}\n",
        "    return success, assignment, stats\n",
        "\n",
        "\n",
        "def check_valid_coloring(adj, colors, k):\n",
        "    \"\"\"\n",
        "    Check that 'colors' is a valid k-coloring for adj.\n",
        "    \"\"\"\n",
        "    adj = np.array(adj, dtype=np.float32)\n",
        "    colors = np.array(colors, dtype=np.int64)\n",
        "    n = adj.shape[0]\n",
        "\n",
        "    if colors.shape[0] != n:\n",
        "        return False\n",
        "    if (colors < 0).any() or (colors >= k).any():\n",
        "        return False\n",
        "\n",
        "    edges = np.argwhere(adj > 0.5)\n",
        "    for u, v in edges:\n",
        "        if u < v and colors[u] == colors[v]:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. GraphData container & dataset generation with hardness\n",
        "# ============================================================\n",
        "\n",
        "class GraphData:\n",
        "    \"\"\"\n",
        "    Container for one graph:\n",
        "    - x: [N, F] float32 node features\n",
        "    - adj: [N, N] float32 adjacency (0/1)\n",
        "    - y: [N] int64 node color labels\n",
        "    - difficulty: backtracks needed by degree-based solver that produced y\n",
        "    \"\"\"\n",
        "    def __init__(self, x, adj, y, difficulty):\n",
        "        self.x = torch.tensor(x, dtype=torch.float32)\n",
        "        self.adj = torch.tensor(adj, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "        self.difficulty = difficulty\n",
        "\n",
        "    @property\n",
        "    def num_nodes(self):\n",
        "        return self.x.size(0)\n",
        "\n",
        "\n",
        "def canonicalize_colors(colors):\n",
        "    \"\"\"\n",
        "    Canonicalize color IDs to 0..C-1 in order of first appearance in node index order.\n",
        "    Only used if USE_CANONICAL_COLORS = True.\n",
        "    \"\"\"\n",
        "    colors = list(colors)\n",
        "    mapping = {}\n",
        "    next_id = 0\n",
        "    canon = []\n",
        "    for c in colors:\n",
        "        if c not in mapping:\n",
        "            mapping[c] = next_id\n",
        "            next_id += 1\n",
        "        canon.append(mapping[c])\n",
        "    return np.array(canon, dtype=np.int64)\n",
        "\n",
        "\n",
        "def generate_colored_graph_with_solver(\n",
        "    k_colors,\n",
        "    n_range,\n",
        "    p_range,\n",
        "    min_backtracks,\n",
        "    max_backtracks,\n",
        "    label_max_backtracks=MAX_LABEL_BACKTRACKS\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate a random Erdos–Renyi graph and:\n",
        "    - run a degree-based backtracking solver with k_colors,\n",
        "    - keep only graphs with backtracks in [min_backtracks, max_backtracks],\n",
        "    - use solver's solution as ground-truth coloring (optionally canonicalized).\n",
        "    Returns: GraphData\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        n = random.randint(*n_range)\n",
        "        p = random.uniform(*p_range)\n",
        "        G = nx.erdos_renyi_graph(n, p)\n",
        "\n",
        "        if G.number_of_edges() == 0:\n",
        "            continue\n",
        "\n",
        "        # Build adjacency\n",
        "        adj = np.zeros((n, n), dtype=np.float32)\n",
        "        for u, v in G.edges():\n",
        "            adj[u, v] = 1.0\n",
        "            adj[v, u] = 1.0\n",
        "\n",
        "        # Degree-based node order\n",
        "        deg = adj.sum(axis=1)\n",
        "        node_order = np.argsort(-deg)\n",
        "\n",
        "        # Solve with k_colors to get label + difficulty\n",
        "        success, assignment, stats = solve_graph_coloring(\n",
        "            adj, k_colors,\n",
        "            node_order=node_order,\n",
        "            init_colors=None,\n",
        "            color_order=None,\n",
        "            max_backtracks=label_max_backtracks\n",
        "        )\n",
        "        if not success:\n",
        "            # either not k-colorable or exceeded label_max_backtracks\n",
        "            continue\n",
        "\n",
        "        backtracks = stats[\"backtracks\"]\n",
        "        if backtracks < min_backtracks or backtracks > max_backtracks:\n",
        "            # too easy or too hard, skip\n",
        "            continue\n",
        "\n",
        "        # Labels\n",
        "        if USE_CANONICAL_COLORS:\n",
        "            colors = canonicalize_colors(assignment)\n",
        "        else:\n",
        "            colors = np.array(assignment, dtype=np.int64)\n",
        "\n",
        "        # Node features:\n",
        "        # - degrees\n",
        "        # - normalized degree\n",
        "        # - clustering coefficient\n",
        "        # - 2-hop degree approximation (normalized)\n",
        "        degrees = np.array([G.degree[i] for i in range(n)], dtype=np.float32)\n",
        "        max_deg = float(degrees.max()) if n > 0 else 1.0\n",
        "        if max_deg <= 0.0:\n",
        "            max_deg = 1.0\n",
        "        deg_norm = degrees / max_deg\n",
        "\n",
        "        clust_dict = nx.clustering(G)\n",
        "        clustering = np.array([clust_dict[i] for i in range(n)], dtype=np.float32)\n",
        "\n",
        "        # 2-hop degree (approx: count of length-2 walks)\n",
        "        adj_mat = adj\n",
        "        two_hop = (adj_mat @ adj_mat).sum(axis=1)  # number of 2-step walks from each node\n",
        "        max_two_hop = float(two_hop.max()) if n > 0 else 1.0\n",
        "        if max_two_hop <= 0.0:\n",
        "            max_two_hop = 1.0\n",
        "        two_hop_norm = two_hop / max_two_hop\n",
        "\n",
        "        x = np.stack([deg_norm, clustering, two_hop_norm, degrees / (n + 1e-6)], axis=1)  # [N, 4]\n",
        "\n",
        "        return GraphData(x, adj, colors, difficulty=backtracks)\n",
        "\n",
        "\n",
        "def generate_dataset_filtered(num_graphs, n_range, p_range, hard_min, hard_max):\n",
        "    \"\"\"\n",
        "    Generate a dataset of GraphData with hardness filtering.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    tries = 0\n",
        "    max_tries = num_graphs * 50  # generous\n",
        "    while len(data) < num_graphs and tries < max_tries:\n",
        "        tries += 1\n",
        "        g = generate_colored_graph_with_solver(\n",
        "            k_colors=K_COLORS,\n",
        "            n_range=n_range,\n",
        "            p_range=p_range,\n",
        "            min_backtracks=hard_min,\n",
        "            max_backtracks=hard_max,\n",
        "            label_max_backtracks=MAX_LABEL_BACKTRACKS\n",
        "        )\n",
        "        data.append(g)\n",
        "        if len(data) % 100 == 0:\n",
        "            print(f\"Generated {len(data)} / {num_graphs} graphs...\")\n",
        "\n",
        "    if len(data) < num_graphs:\n",
        "        print(f\"[WARNING] only generated {len(data)} graphs out of requested {num_graphs}\")\n",
        "\n",
        "    random.shuffle(data)\n",
        "    return data\n",
        "\n",
        "\n",
        "def build_datasets():\n",
        "    \"\"\"\n",
        "    Generate and split the dataset into train / val / test for chosen regime.\n",
        "    \"\"\"\n",
        "    cfg = REGIMES[REGIME]\n",
        "    print(f\"\\n=== Building dataset for regime: {REGIME} ===\")\n",
        "    print(f\"n_range = {cfg['n_range']}, p_range = {cfg['p_range']}, \"\n",
        "          f\"hard_min = {cfg['hard_min']}, hard_max = {cfg['hard_max']}\")\n",
        "\n",
        "    all_graphs = generate_dataset_filtered(\n",
        "        NUM_TOTAL,\n",
        "        n_range=cfg[\"n_range\"],\n",
        "        p_range=cfg[\"p_range\"],\n",
        "        hard_min=cfg[\"hard_min\"],\n",
        "        hard_max=cfg[\"hard_max\"]\n",
        "    )\n",
        "    print(\"Total graphs generated:\", len(all_graphs))\n",
        "\n",
        "    train_graphs = all_graphs[:NUM_TRAIN]\n",
        "    val_graphs   = all_graphs[NUM_TRAIN:NUM_TRAIN + NUM_VAL]\n",
        "    test_graphs  = all_graphs[NUM_TRAIN + NUM_VAL:NUM_TOTAL]\n",
        "\n",
        "    print(f\"Train: {len(train_graphs)}, Val: {len(val_graphs)}, Test: {len(test_graphs)}\")\n",
        "\n",
        "    # Quick sanity: show some sizes & difficulties\n",
        "    print(\"Example train graph sizes:\",\n",
        "          [g.num_nodes for g in train_graphs[:10]])\n",
        "    print(\"Example train graph difficulties (backtracks):\",\n",
        "          [g.difficulty for g in train_graphs[:10]])\n",
        "\n",
        "    d_train = np.array([g.difficulty for g in train_graphs])\n",
        "    print(\"Train difficulty stats (backtracks):\",\n",
        "          \"min =\", d_train.min(),\n",
        "          \"median =\", np.median(d_train),\n",
        "          \"max =\", d_train.max())\n",
        "\n",
        "    # Label distribution sanity check\n",
        "    all_y = np.concatenate([g.y.numpy() for g in train_graphs])\n",
        "    hist = np.bincount(all_y, minlength=K_COLORS)\n",
        "    print(\"Global train label distribution (freq):\", hist)\n",
        "    print(\"Global train label distribution (proportions):\", hist / hist.sum())\n",
        "\n",
        "    return train_graphs, val_graphs, test_graphs\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3. Models: GCN, Residual GCN, MLP\n",
        "# ============================================================\n",
        "\n",
        "class GCNLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    One GCN layer using symmetric normalization:\n",
        "    H' = D^{-1/2} (A + I) D^{-1/2} H W\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(in_dim, out_dim)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        \"\"\"\n",
        "        x: [N, F]\n",
        "        adj: [N, N] (0/1)\n",
        "        \"\"\"\n",
        "        N = adj.size(0)\n",
        "        I = torch.eye(N, device=adj.device)\n",
        "        A_hat = adj + I\n",
        "        deg = A_hat.sum(dim=1)              # [N]\n",
        "        D_inv_sqrt = deg.pow(-0.5)\n",
        "        D_inv_sqrt[torch.isinf(D_inv_sqrt)] = 0.0\n",
        "        norm_adj = D_inv_sqrt.unsqueeze(1) * A_hat * D_inv_sqrt.unsqueeze(0)  # [N, N]\n",
        "        h = torch.matmul(norm_adj, x)      # [N, F]\n",
        "        return self.linear(h)              # [N, out_dim]\n",
        "\n",
        "\n",
        "class GCNColoring(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-layer GCN with dropout for node-wise color prediction.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim, hidden_dim, num_colors, num_layers=4, dropout=0.05):\n",
        "        super().__init__()\n",
        "        assert num_layers >= 2\n",
        "        layers = []\n",
        "        layers.append(GCNLayer(in_dim, hidden_dim))\n",
        "        for _ in range(num_layers - 2):\n",
        "            layers.append(GCNLayer(hidden_dim, hidden_dim))\n",
        "        layers.append(GCNLayer(hidden_dim, hidden_dim))\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        self.out_linear = nn.Linear(hidden_dim, num_colors)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        h = x\n",
        "        for layer in self.layers:\n",
        "            h = layer(h, adj)\n",
        "            h = F.relu(h)\n",
        "            h = self.dropout(h)\n",
        "        logits = self.out_linear(h)  # [N, num_colors]\n",
        "        return logits\n",
        "\n",
        "\n",
        "class ResGCNBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Residual GCN block: GCNLayer + residual + LayerNorm.\n",
        "    \"\"\"\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.gcn = GCNLayer(dim, dim)\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        out = self.gcn(x, adj)\n",
        "        out = out + x\n",
        "        out = F.relu(out)\n",
        "        return self.norm(out)\n",
        "\n",
        "\n",
        "class ResGCNColoring(nn.Module):\n",
        "    \"\"\"\n",
        "    Stronger residual GCN:\n",
        "    - input projection\n",
        "    - several ResGCNBlock layers\n",
        "    - output layer\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim, hidden_dim, num_colors, num_blocks=5, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.in_linear = nn.Linear(in_dim, hidden_dim)\n",
        "        self.blocks = nn.ModuleList([ResGCNBlock(hidden_dim) for _ in range(num_blocks)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out_linear = nn.Linear(hidden_dim, num_colors)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        h = F.relu(self.in_linear(x))\n",
        "        for block in self.blocks:\n",
        "            h = block(h, adj)\n",
        "            h = self.dropout(h)\n",
        "        logits = self.out_linear(h)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class MLPColoring(nn.Module):\n",
        "    \"\"\"\n",
        "    Optional baseline: ignores adj, uses only node features.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim, hidden_dim, num_colors, num_layers=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "        dims = [in_dim] + [hidden_dim] * (num_layers - 1)\n",
        "        layers = []\n",
        "        for d_in, d_out in zip(dims[:-1], dims[1:]):\n",
        "            layers.append(nn.Linear(d_in, d_out))\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        self.out_linear = nn.Linear(hidden_dim, num_colors)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        h = x\n",
        "        for layer in self.layers:\n",
        "            h = F.relu(layer(h))\n",
        "            h = self.dropout(h)\n",
        "        return self.out_linear(h)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. GNN evaluation helpers (GNN-only metrics)\n",
        "# ============================================================\n",
        "\n",
        "def evaluate_gnn(model, graphs, device=DEVICE, k_colors=K_COLORS):\n",
        "    \"\"\"\n",
        "    Evaluate GNN alone (no solver):\n",
        "    - node accuracy\n",
        "    - graph-level exact accuracy\n",
        "    - edge violation rate\n",
        "    - valid-coloring rate (no same-color edge)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_nodes = 0\n",
        "    correct_nodes = 0\n",
        "    total_graphs = len(graphs)\n",
        "    exact_graphs = 0\n",
        "\n",
        "    total_edges = 0\n",
        "    total_violations = 0\n",
        "    valid_colorings = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for g in graphs:\n",
        "            x = g.x.to(device)\n",
        "            adj = g.adj.to(device)\n",
        "            y = g.y.to(device)\n",
        "\n",
        "            logits = model(x, adj)\n",
        "            pred = logits.argmax(dim=1)           # [N]\n",
        "\n",
        "            correct = (pred == y).sum().item()\n",
        "            total_nodes += y.size(0)\n",
        "            correct_nodes += correct\n",
        "            if correct == y.size(0):\n",
        "                exact_graphs += 1\n",
        "\n",
        "            edges = (g.adj > 0.5).nonzero(as_tuple=False)\n",
        "            if edges.numel() > 0:\n",
        "                u = edges[:, 0]\n",
        "                v = edges[:, 1]\n",
        "                mask = u < v\n",
        "                u = u[mask]\n",
        "                v = v[mask]\n",
        "                if u.numel() > 0:\n",
        "                    same_color = (pred[u] == pred[v]).float()\n",
        "                    total_violations += same_color.sum().item()\n",
        "                    total_edges += u.numel()\n",
        "\n",
        "                    if same_color.sum().item() == 0:\n",
        "                        valid_colorings += 1\n",
        "                else:\n",
        "                    valid_colorings += 1\n",
        "            else:\n",
        "                valid_colorings += 1\n",
        "\n",
        "    node_acc = correct_nodes / total_nodes\n",
        "    exact_rate = exact_graphs / total_graphs\n",
        "    viol_rate = (total_violations / total_edges) if total_edges > 0 else 0.0\n",
        "    valid_rate = valid_colorings / total_graphs\n",
        "\n",
        "    return {\n",
        "        \"node_acc\": node_acc,\n",
        "        \"graph_exact\": exact_rate,\n",
        "        \"edge_violation\": viol_rate,\n",
        "        \"gnn_valid_colorings\": valid_rate,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. Training loop with early stopping\n",
        "# ============================================================\n",
        "\n",
        "def train_gnn(\n",
        "    model,\n",
        "    train_graphs,\n",
        "    val_graphs,\n",
        "    use_violation_loss=USE_VIOLATION_LOSS,\n",
        "    lambda_viol=LAMBDA_VIOL,\n",
        "    epochs=EPOCHS,\n",
        "    patience=PATIENCE,\n",
        "    device=DEVICE\n",
        "):\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=LR,\n",
        "        weight_decay=WEIGHT_DECAY\n",
        "    )\n",
        "\n",
        "    print(model)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    best_state = None\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        random.shuffle(train_graphs)\n",
        "        total_loss = 0.0\n",
        "        total_nodes = 0\n",
        "\n",
        "        for g in train_graphs:\n",
        "            x = g.x.to(device)\n",
        "            adj = g.adj.to(device)\n",
        "            y = g.y.to(device)\n",
        "\n",
        "            logits = model(x, adj)\n",
        "            ce_loss = F.cross_entropy(logits, y)\n",
        "\n",
        "            if use_violation_loss:\n",
        "                with torch.no_grad():\n",
        "                    edges = (adj > 0.5).nonzero(as_tuple=False)\n",
        "                if edges.numel() > 0:\n",
        "                    prob = F.softmax(logits, dim=1)\n",
        "                    u = edges[:, 0]\n",
        "                    v = edges[:, 1]\n",
        "                    mask = u < v\n",
        "                    u = u[mask]\n",
        "                    v = v[mask]\n",
        "                    if u.numel() > 0:\n",
        "                        same_prob = (prob[u] * prob[v]).sum(dim=1)\n",
        "                        loss_viol = same_prob.mean()\n",
        "                        loss = ce_loss + lambda_viol * loss_viol\n",
        "                    else:\n",
        "                        loss = ce_loss\n",
        "                else:\n",
        "                    loss = ce_loss\n",
        "            else:\n",
        "                loss = ce_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * g.num_nodes\n",
        "            total_nodes += g.num_nodes\n",
        "\n",
        "        train_loss = total_loss / total_nodes\n",
        "        val_metrics = evaluate_gnn(model, val_graphs, device, K_COLORS)\n",
        "        val_acc = val_metrics[\"node_acc\"]\n",
        "        val_viol = val_metrics[\"edge_violation\"]\n",
        "        val_valid = val_metrics[\"gnn_valid_colorings\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | train_loss = {train_loss:.4f} | \"\n",
        "            f\"val_node_acc = {val_acc:.3f} | \"\n",
        "            f\"val_edge_violation = {val_viol:.3f} | \"\n",
        "            f\"val_gnn_valid = {val_valid:.3f}\"\n",
        "        )\n",
        "\n",
        "        # Early stopping on validation node accuracy\n",
        "        if val_acc > best_val_acc + 1e-4:\n",
        "            best_val_acc = val_acc\n",
        "            best_state = copy.deepcopy(model.state_dict())\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch}, best val_node_acc = {best_val_acc:.3f}\")\n",
        "                break\n",
        "\n",
        "    # Load best model\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "        print(\"Loaded best validation checkpoint.\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. Solver evaluation with/without GNN guidance\n",
        "# ============================================================\n",
        "\n",
        "def eval_solvers_on_dataset(\n",
        "    graphs,\n",
        "    model,\n",
        "    device=DEVICE,\n",
        "    k_colors=K_COLORS,\n",
        "    max_backtracks=5000\n",
        "):\n",
        "    \"\"\"\n",
        "    Compare strategies:\n",
        "    - 'random': random node order, no GNN\n",
        "    - 'degree': high-degree-first node order, no GNN\n",
        "    - 'gnn_ordering': order nodes by GNN confidence, use GNN color ranking\n",
        "    - 'gnn_warm_start': degree order + GNN color ranking\n",
        "    - 'gnn_both': GNN ordering + GNN color ranking\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    methods = [\"random\", \"degree\", \"gnn_ordering\", \"gnn_warm_start\", \"gnn_both\"]\n",
        "    stats = {\n",
        "        m: {\n",
        "            \"success\": [],\n",
        "            \"backtracks\": [],\n",
        "            \"steps\": [],\n",
        "            \"runtime\": [],\n",
        "        } for m in methods\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for g in graphs:\n",
        "            adj_np = g.adj.cpu().numpy()\n",
        "            n = g.num_nodes\n",
        "            deg = adj_np.sum(axis=1)\n",
        "\n",
        "            x = g.x.to(device)\n",
        "            adj = g.adj.to(device)\n",
        "            logits = model(x, adj)\n",
        "            prob = F.softmax(logits, dim=1).cpu().numpy()   # [N, K]\n",
        "            gnn_colors = prob.argmax(axis=1)\n",
        "            gnn_confidence = prob.max(axis=1)\n",
        "            color_order = np.argsort(-prob, axis=1)         # [N, K]\n",
        "\n",
        "            for method in methods:\n",
        "                if method == \"random\":\n",
        "                    node_order = np.random.permutation(n)\n",
        "                    init_colors = None\n",
        "                    method_color_order = None\n",
        "\n",
        "                elif method == \"degree\":\n",
        "                    node_order = np.argsort(-deg)\n",
        "                    init_colors = None\n",
        "                    method_color_order = None\n",
        "\n",
        "                elif method == \"gnn_ordering\":\n",
        "                    node_order = np.argsort(-gnn_confidence)\n",
        "                    init_colors = None\n",
        "                    method_color_order = color_order\n",
        "\n",
        "                elif method == \"gnn_warm_start\":\n",
        "                    node_order = np.argsort(-deg)\n",
        "                    init_colors = None\n",
        "                    method_color_order = color_order\n",
        "\n",
        "                elif method == \"gnn_both\":\n",
        "                    node_order = np.argsort(-gnn_confidence)\n",
        "                    init_colors = None\n",
        "                    method_color_order = color_order\n",
        "\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "                t0 = time.time()\n",
        "                success, assignment, s = solve_graph_coloring(\n",
        "                    adj_np, k_colors,\n",
        "                    node_order=node_order,\n",
        "                    init_colors=init_colors,\n",
        "                    color_order=method_color_order,\n",
        "                    max_backtracks=max_backtracks\n",
        "                )\n",
        "                elapsed = time.time() - t0\n",
        "\n",
        "                if success:\n",
        "                    valid = check_valid_coloring(adj_np, assignment, k_colors)\n",
        "                    if not valid:\n",
        "                        print(\"[WARNING] invalid coloring despite success for method\", method)\n",
        "\n",
        "                stats[method][\"success\"].append(1 if success else 0)\n",
        "                stats[method][\"backtracks\"].append(s[\"backtracks\"])\n",
        "                stats[method][\"steps\"].append(s[\"steps\"])\n",
        "                stats[method][\"runtime\"].append(elapsed)\n",
        "\n",
        "    summary = {}\n",
        "    for method in methods:\n",
        "        s = stats[method]\n",
        "        success_rate = np.mean(s[\"success\"])\n",
        "        avg_backtracks = np.mean(s[\"backtracks\"])\n",
        "        avg_steps = np.mean(s[\"steps\"])\n",
        "        avg_runtime = np.mean(s[\"runtime\"])\n",
        "\n",
        "        summary[method] = {\n",
        "            \"success_rate\": success_rate,\n",
        "            \"avg_backtracks\": avg_backtracks,\n",
        "            \"avg_steps\": avg_steps,\n",
        "            \"avg_runtime_sec\": avg_runtime,\n",
        "        }\n",
        "\n",
        "    return summary, stats\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7. Debug: Overfit a single graph (sanity check)\n",
        "# ============================================================\n",
        "\n",
        "def debug_overfit_single_graph(graph):\n",
        "    \"\"\"\n",
        "    Optional: sanity check that the model *can* learn at all by overfitting 1 graph.\n",
        "    \"\"\"\n",
        "    print(\"\\n[DEBUG] Overfitting a single graph...\")\n",
        "    if MODEL_TYPE == \"gcn\":\n",
        "        model = GCNColoring(\n",
        "            in_dim=NODE_FEATURE_DIM,\n",
        "            hidden_dim=HIDDEN_DIM,\n",
        "            num_colors=K_COLORS,\n",
        "            num_layers=NUM_LAYERS,\n",
        "            dropout=0.0\n",
        "        ).to(DEVICE)\n",
        "    elif MODEL_TYPE == \"resgcn\":\n",
        "        model = ResGCNColoring(\n",
        "            in_dim=NODE_FEATURE_DIM,\n",
        "            hidden_dim=HIDDEN_DIM,\n",
        "            num_colors=K_COLORS,\n",
        "            num_blocks=5,\n",
        "            dropout=0.0\n",
        "        ).to(DEVICE)\n",
        "    else:\n",
        "        model = MLPColoring(\n",
        "            in_dim=NODE_FEATURE_DIM,\n",
        "            hidden_dim=HIDDEN_DIM,\n",
        "            num_colors=K_COLORS,\n",
        "            num_layers=3,\n",
        "            dropout=0.0\n",
        "        ).to(DEVICE)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.0)\n",
        "\n",
        "    for epoch in range(1, 501):\n",
        "        model.train()\n",
        "        x = graph.x.to(DEVICE)\n",
        "        adj = graph.adj.to(DEVICE)\n",
        "        y = graph.y.to(DEVICE)\n",
        "\n",
        "        logits = model(x, adj)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = logits.argmax(dim=1)\n",
        "        acc = (pred == y).float().mean().item()\n",
        "\n",
        "        if epoch % 50 == 0 or acc == 1.0:\n",
        "            print(f\"[Single-graph] Epoch {epoch}, loss={loss.item():.4f}, acc={acc:.3f}\")\n",
        "        if acc == 1.0:\n",
        "            print(\"[Single-graph] Reached 100% training accuracy.\")\n",
        "            break\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8. Main script\n",
        "# ============================================================\n",
        "\n",
        "def main():\n",
        "    # 1) Build datasets\n",
        "    train_graphs, val_graphs, test_graphs = build_datasets()\n",
        "\n",
        "    if RUN_SINGLE_GRAPH_DEBUG:\n",
        "        debug_overfit_single_graph(train_graphs[0])\n",
        "\n",
        "    # 2) Create model (ResGCN / GCN / MLP)\n",
        "    if MODEL_TYPE == \"gcn\":\n",
        "        model = GCNColoring(\n",
        "            in_dim=NODE_FEATURE_DIM,\n",
        "            hidden_dim=HIDDEN_DIM,\n",
        "            num_colors=K_COLORS,\n",
        "            num_layers=NUM_LAYERS,\n",
        "            dropout=0.05\n",
        "        ).to(DEVICE)\n",
        "    elif MODEL_TYPE == \"resgcn\":\n",
        "        model = ResGCNColoring(\n",
        "            in_dim=NODE_FEATURE_DIM,\n",
        "            hidden_dim=HIDDEN_DIM,\n",
        "            num_colors=K_COLORS,\n",
        "            num_blocks=5,\n",
        "            dropout=0.1\n",
        "        ).to(DEVICE)\n",
        "    elif MODEL_TYPE == \"mlp\":\n",
        "        model = MLPColoring(\n",
        "            in_dim=NODE_FEATURE_DIM,\n",
        "            hidden_dim=HIDDEN_DIM,\n",
        "            num_colors=K_COLORS,\n",
        "            num_layers=3,\n",
        "            dropout=0.1\n",
        "        ).to(DEVICE)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown MODEL_TYPE: {MODEL_TYPE}\")\n",
        "\n",
        "    # 3) Train with early stopping\n",
        "    model = train_gnn(\n",
        "        model,\n",
        "        train_graphs,\n",
        "        val_graphs,\n",
        "        use_violation_loss=USE_VIOLATION_LOSS,\n",
        "        lambda_viol=LAMBDA_VIOL,\n",
        "        epochs=EPOCHS,\n",
        "        patience=PATIENCE,\n",
        "        device=DEVICE\n",
        "    )\n",
        "\n",
        "    # 4) GNN-only test metrics\n",
        "    test_metrics = evaluate_gnn(model, test_graphs, DEVICE, K_COLORS)\n",
        "    print(\"\\n=== GNN-only test metrics ===\")\n",
        "    for k, v in test_metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    # 5) Solver performance with/without GNN\n",
        "    solver_summary, solver_raw = eval_solvers_on_dataset(\n",
        "        test_graphs,\n",
        "        model,\n",
        "        DEVICE,\n",
        "        K_COLORS,\n",
        "        max_backtracks=5000\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Solver performance on test set (with/without GNN) ===\")\n",
        "    for method, s in solver_summary.items():\n",
        "        print(f\"\\nMethod: {method}\")\n",
        "        for key, val in s.items():\n",
        "            if \"time\" in key:\n",
        "                print(f\"  {key}: {val:.6f}\")\n",
        "            else:\n",
        "                print(f\"  {key}: {val:.3f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvN5WAhHmhOS",
        "outputId": "af1a9a2f-d62b-4b46-e34f-e9414c1f4beb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "=== Building dataset for regime: easy ===\n",
            "n_range = (10, 18), p_range = (0.2, 0.45), hard_min = 5, hard_max = 150\n",
            "Generated 100 / 1400 graphs...\n",
            "Generated 200 / 1400 graphs...\n",
            "Generated 300 / 1400 graphs...\n",
            "Generated 400 / 1400 graphs...\n",
            "Generated 500 / 1400 graphs...\n",
            "Generated 600 / 1400 graphs...\n",
            "Generated 700 / 1400 graphs...\n",
            "Generated 800 / 1400 graphs...\n",
            "Generated 900 / 1400 graphs...\n",
            "Generated 1000 / 1400 graphs...\n",
            "Generated 1100 / 1400 graphs...\n",
            "Generated 1200 / 1400 graphs...\n",
            "Generated 1300 / 1400 graphs...\n",
            "Generated 1400 / 1400 graphs...\n",
            "Total graphs generated: 1400\n",
            "Train: 1000, Val: 200, Test: 200\n",
            "Example train graph sizes: [16, 18, 18, 16, 16, 17, 13, 18, 17, 18]\n",
            "Example train graph difficulties (backtracks): [75, 58, 9, 13, 28, 8, 11, 7, 13, 133]\n",
            "Train difficulty stats (backtracks): min = 5 median = 15.0 max = 148\n",
            "Global train label distribution (freq): [4006 4203 4149 3570]\n",
            "Global train label distribution (proportions): [0.25150678 0.26387494 0.26048468 0.2241336 ]\n",
            "ResGCNColoring(\n",
            "  (in_linear): Linear(in_features=4, out_features=256, bias=True)\n",
            "  (blocks): ModuleList(\n",
            "    (0-4): 5 x ResGCNBlock(\n",
            "      (gcn): GCNLayer(\n",
            "        (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "      )\n",
            "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (out_linear): Linear(in_features=256, out_features=4, bias=True)\n",
            ")\n",
            "Epoch 001 | train_loss = 1.3799 | val_node_acc = 0.329 | val_edge_violation = 0.286 | val_gnn_valid = 0.000\n",
            "Epoch 002 | train_loss = 1.3427 | val_node_acc = 0.377 | val_edge_violation = 0.256 | val_gnn_valid = 0.000\n",
            "Epoch 003 | train_loss = 1.2644 | val_node_acc = 0.425 | val_edge_violation = 0.191 | val_gnn_valid = 0.000\n",
            "Epoch 004 | train_loss = 1.1982 | val_node_acc = 0.464 | val_edge_violation = 0.227 | val_gnn_valid = 0.000\n",
            "Epoch 005 | train_loss = 1.1651 | val_node_acc = 0.482 | val_edge_violation = 0.162 | val_gnn_valid = 0.000\n",
            "Epoch 006 | train_loss = 1.1451 | val_node_acc = 0.512 | val_edge_violation = 0.133 | val_gnn_valid = 0.000\n",
            "Epoch 007 | train_loss = 1.1282 | val_node_acc = 0.527 | val_edge_violation = 0.138 | val_gnn_valid = 0.005\n",
            "Epoch 008 | train_loss = 1.1178 | val_node_acc = 0.485 | val_edge_violation = 0.188 | val_gnn_valid = 0.010\n",
            "Epoch 009 | train_loss = 1.1128 | val_node_acc = 0.531 | val_edge_violation = 0.137 | val_gnn_valid = 0.010\n",
            "Epoch 010 | train_loss = 1.1016 | val_node_acc = 0.534 | val_edge_violation = 0.140 | val_gnn_valid = 0.010\n",
            "Epoch 011 | train_loss = 1.0993 | val_node_acc = 0.538 | val_edge_violation = 0.144 | val_gnn_valid = 0.000\n",
            "Epoch 012 | train_loss = 1.0972 | val_node_acc = 0.533 | val_edge_violation = 0.117 | val_gnn_valid = 0.005\n",
            "Epoch 013 | train_loss = 1.0966 | val_node_acc = 0.515 | val_edge_violation = 0.144 | val_gnn_valid = 0.010\n",
            "Epoch 014 | train_loss = 1.1007 | val_node_acc = 0.524 | val_edge_violation = 0.129 | val_gnn_valid = 0.015\n",
            "Epoch 015 | train_loss = 1.0916 | val_node_acc = 0.495 | val_edge_violation = 0.210 | val_gnn_valid = 0.005\n",
            "Epoch 016 | train_loss = 1.0872 | val_node_acc = 0.522 | val_edge_violation = 0.219 | val_gnn_valid = 0.005\n",
            "Epoch 017 | train_loss = 1.0856 | val_node_acc = 0.546 | val_edge_violation = 0.124 | val_gnn_valid = 0.005\n",
            "Epoch 018 | train_loss = 1.0818 | val_node_acc = 0.531 | val_edge_violation = 0.118 | val_gnn_valid = 0.000\n",
            "Epoch 019 | train_loss = 1.0802 | val_node_acc = 0.540 | val_edge_violation = 0.137 | val_gnn_valid = 0.015\n",
            "Epoch 020 | train_loss = 1.0806 | val_node_acc = 0.519 | val_edge_violation = 0.159 | val_gnn_valid = 0.005\n",
            "Epoch 021 | train_loss = 1.0785 | val_node_acc = 0.533 | val_edge_violation = 0.110 | val_gnn_valid = 0.010\n",
            "Epoch 022 | train_loss = 1.0786 | val_node_acc = 0.543 | val_edge_violation = 0.134 | val_gnn_valid = 0.010\n",
            "Epoch 023 | train_loss = 1.0686 | val_node_acc = 0.541 | val_edge_violation = 0.161 | val_gnn_valid = 0.005\n",
            "Epoch 024 | train_loss = 1.0699 | val_node_acc = 0.540 | val_edge_violation = 0.147 | val_gnn_valid = 0.005\n",
            "Epoch 025 | train_loss = 1.0675 | val_node_acc = 0.543 | val_edge_violation = 0.121 | val_gnn_valid = 0.010\n",
            "Epoch 026 | train_loss = 1.0717 | val_node_acc = 0.530 | val_edge_violation = 0.130 | val_gnn_valid = 0.005\n",
            "Epoch 027 | train_loss = 1.0672 | val_node_acc = 0.538 | val_edge_violation = 0.148 | val_gnn_valid = 0.005\n",
            "Epoch 028 | train_loss = 1.0713 | val_node_acc = 0.528 | val_edge_violation = 0.173 | val_gnn_valid = 0.000\n",
            "Epoch 029 | train_loss = 1.0680 | val_node_acc = 0.538 | val_edge_violation = 0.134 | val_gnn_valid = 0.010\n",
            "Epoch 030 | train_loss = 1.0623 | val_node_acc = 0.518 | val_edge_violation = 0.141 | val_gnn_valid = 0.005\n",
            "Epoch 031 | train_loss = 1.0650 | val_node_acc = 0.543 | val_edge_violation = 0.117 | val_gnn_valid = 0.010\n",
            "Epoch 032 | train_loss = 1.0578 | val_node_acc = 0.544 | val_edge_violation = 0.099 | val_gnn_valid = 0.020\n",
            "Epoch 033 | train_loss = 1.0682 | val_node_acc = 0.539 | val_edge_violation = 0.143 | val_gnn_valid = 0.000\n",
            "Epoch 034 | train_loss = 1.0617 | val_node_acc = 0.553 | val_edge_violation = 0.123 | val_gnn_valid = 0.000\n",
            "Epoch 035 | train_loss = 1.0689 | val_node_acc = 0.551 | val_edge_violation = 0.109 | val_gnn_valid = 0.005\n",
            "Epoch 036 | train_loss = 1.0550 | val_node_acc = 0.555 | val_edge_violation = 0.097 | val_gnn_valid = 0.020\n",
            "Epoch 037 | train_loss = 1.0620 | val_node_acc = 0.549 | val_edge_violation = 0.124 | val_gnn_valid = 0.015\n",
            "Epoch 038 | train_loss = 1.0572 | val_node_acc = 0.536 | val_edge_violation = 0.117 | val_gnn_valid = 0.005\n",
            "Epoch 039 | train_loss = 1.0631 | val_node_acc = 0.559 | val_edge_violation = 0.102 | val_gnn_valid = 0.010\n",
            "Epoch 040 | train_loss = 1.0603 | val_node_acc = 0.541 | val_edge_violation = 0.171 | val_gnn_valid = 0.000\n",
            "Epoch 041 | train_loss = 1.0472 | val_node_acc = 0.548 | val_edge_violation = 0.117 | val_gnn_valid = 0.005\n",
            "Epoch 042 | train_loss = 1.0557 | val_node_acc = 0.561 | val_edge_violation = 0.110 | val_gnn_valid = 0.015\n",
            "Epoch 043 | train_loss = 1.0575 | val_node_acc = 0.541 | val_edge_violation = 0.132 | val_gnn_valid = 0.000\n",
            "Epoch 044 | train_loss = 1.0499 | val_node_acc = 0.547 | val_edge_violation = 0.128 | val_gnn_valid = 0.010\n",
            "Epoch 045 | train_loss = 1.0531 | val_node_acc = 0.548 | val_edge_violation = 0.113 | val_gnn_valid = 0.015\n",
            "Epoch 046 | train_loss = 1.0586 | val_node_acc = 0.546 | val_edge_violation = 0.127 | val_gnn_valid = 0.005\n",
            "Epoch 047 | train_loss = 1.0514 | val_node_acc = 0.546 | val_edge_violation = 0.145 | val_gnn_valid = 0.000\n",
            "Epoch 048 | train_loss = 1.0515 | val_node_acc = 0.558 | val_edge_violation = 0.108 | val_gnn_valid = 0.000\n",
            "Epoch 049 | train_loss = 1.0509 | val_node_acc = 0.541 | val_edge_violation = 0.131 | val_gnn_valid = 0.000\n",
            "Epoch 050 | train_loss = 1.0457 | val_node_acc = 0.547 | val_edge_violation = 0.111 | val_gnn_valid = 0.010\n",
            "Epoch 051 | train_loss = 1.0530 | val_node_acc = 0.554 | val_edge_violation = 0.113 | val_gnn_valid = 0.010\n",
            "Epoch 052 | train_loss = 1.0466 | val_node_acc = 0.546 | val_edge_violation = 0.111 | val_gnn_valid = 0.005\n",
            "Epoch 053 | train_loss = 1.0490 | val_node_acc = 0.561 | val_edge_violation = 0.107 | val_gnn_valid = 0.010\n",
            "Epoch 054 | train_loss = 1.0519 | val_node_acc = 0.552 | val_edge_violation = 0.103 | val_gnn_valid = 0.010\n",
            "Epoch 055 | train_loss = 1.0485 | val_node_acc = 0.547 | val_edge_violation = 0.109 | val_gnn_valid = 0.010\n",
            "Epoch 056 | train_loss = 1.0390 | val_node_acc = 0.550 | val_edge_violation = 0.151 | val_gnn_valid = 0.000\n",
            "Epoch 057 | train_loss = 1.0536 | val_node_acc = 0.551 | val_edge_violation = 0.095 | val_gnn_valid = 0.005\n",
            "Epoch 058 | train_loss = 1.0435 | val_node_acc = 0.560 | val_edge_violation = 0.108 | val_gnn_valid = 0.010\n",
            "Epoch 059 | train_loss = 1.0399 | val_node_acc = 0.557 | val_edge_violation = 0.117 | val_gnn_valid = 0.000\n",
            "Epoch 060 | train_loss = 1.0475 | val_node_acc = 0.528 | val_edge_violation = 0.132 | val_gnn_valid = 0.005\n",
            "Epoch 061 | train_loss = 1.0453 | val_node_acc = 0.544 | val_edge_violation = 0.126 | val_gnn_valid = 0.005\n",
            "Epoch 062 | train_loss = 1.0340 | val_node_acc = 0.564 | val_edge_violation = 0.101 | val_gnn_valid = 0.015\n",
            "Epoch 063 | train_loss = 1.0385 | val_node_acc = 0.550 | val_edge_violation = 0.139 | val_gnn_valid = 0.000\n",
            "Epoch 064 | train_loss = 1.0432 | val_node_acc = 0.568 | val_edge_violation = 0.104 | val_gnn_valid = 0.015\n",
            "Epoch 065 | train_loss = 1.0366 | val_node_acc = 0.545 | val_edge_violation = 0.190 | val_gnn_valid = 0.005\n",
            "Epoch 066 | train_loss = 1.0431 | val_node_acc = 0.558 | val_edge_violation = 0.116 | val_gnn_valid = 0.010\n",
            "Epoch 067 | train_loss = 1.0423 | val_node_acc = 0.557 | val_edge_violation = 0.116 | val_gnn_valid = 0.000\n",
            "Epoch 068 | train_loss = 1.0343 | val_node_acc = 0.552 | val_edge_violation = 0.148 | val_gnn_valid = 0.005\n",
            "Epoch 069 | train_loss = 1.0304 | val_node_acc = 0.568 | val_edge_violation = 0.120 | val_gnn_valid = 0.000\n",
            "Epoch 070 | train_loss = 1.0386 | val_node_acc = 0.561 | val_edge_violation = 0.103 | val_gnn_valid = 0.015\n",
            "Epoch 071 | train_loss = 1.0384 | val_node_acc = 0.566 | val_edge_violation = 0.111 | val_gnn_valid = 0.000\n",
            "Epoch 072 | train_loss = 1.0300 | val_node_acc = 0.569 | val_edge_violation = 0.120 | val_gnn_valid = 0.010\n",
            "Epoch 073 | train_loss = 1.0346 | val_node_acc = 0.556 | val_edge_violation = 0.114 | val_gnn_valid = 0.010\n",
            "Epoch 074 | train_loss = 1.0328 | val_node_acc = 0.556 | val_edge_violation = 0.121 | val_gnn_valid = 0.000\n",
            "Epoch 075 | train_loss = 1.0306 | val_node_acc = 0.562 | val_edge_violation = 0.109 | val_gnn_valid = 0.000\n",
            "Epoch 076 | train_loss = 1.0443 | val_node_acc = 0.560 | val_edge_violation = 0.138 | val_gnn_valid = 0.000\n",
            "Epoch 077 | train_loss = 1.0297 | val_node_acc = 0.573 | val_edge_violation = 0.102 | val_gnn_valid = 0.010\n",
            "Epoch 078 | train_loss = 1.0329 | val_node_acc = 0.561 | val_edge_violation = 0.106 | val_gnn_valid = 0.005\n",
            "Epoch 079 | train_loss = 1.0346 | val_node_acc = 0.548 | val_edge_violation = 0.142 | val_gnn_valid = 0.000\n",
            "Epoch 080 | train_loss = 1.0282 | val_node_acc = 0.562 | val_edge_violation = 0.098 | val_gnn_valid = 0.010\n",
            "Epoch 081 | train_loss = 1.0378 | val_node_acc = 0.562 | val_edge_violation = 0.106 | val_gnn_valid = 0.000\n",
            "Epoch 082 | train_loss = 1.0359 | val_node_acc = 0.574 | val_edge_violation = 0.119 | val_gnn_valid = 0.005\n",
            "Epoch 083 | train_loss = 1.0268 | val_node_acc = 0.562 | val_edge_violation = 0.094 | val_gnn_valid = 0.010\n",
            "Epoch 084 | train_loss = 1.0260 | val_node_acc = 0.572 | val_edge_violation = 0.124 | val_gnn_valid = 0.005\n",
            "Epoch 085 | train_loss = 1.0337 | val_node_acc = 0.572 | val_edge_violation = 0.122 | val_gnn_valid = 0.010\n",
            "Epoch 086 | train_loss = 1.0288 | val_node_acc = 0.564 | val_edge_violation = 0.102 | val_gnn_valid = 0.025\n",
            "Epoch 087 | train_loss = 1.0320 | val_node_acc = 0.562 | val_edge_violation = 0.127 | val_gnn_valid = 0.005\n",
            "Epoch 088 | train_loss = 1.0381 | val_node_acc = 0.530 | val_edge_violation = 0.170 | val_gnn_valid = 0.010\n",
            "Epoch 089 | train_loss = 1.0248 | val_node_acc = 0.559 | val_edge_violation = 0.102 | val_gnn_valid = 0.015\n",
            "Epoch 090 | train_loss = 1.0297 | val_node_acc = 0.577 | val_edge_violation = 0.120 | val_gnn_valid = 0.000\n",
            "Epoch 091 | train_loss = 1.0208 | val_node_acc = 0.565 | val_edge_violation = 0.126 | val_gnn_valid = 0.005\n",
            "Epoch 092 | train_loss = 1.0198 | val_node_acc = 0.549 | val_edge_violation = 0.116 | val_gnn_valid = 0.010\n",
            "Epoch 093 | train_loss = 1.0299 | val_node_acc = 0.548 | val_edge_violation = 0.113 | val_gnn_valid = 0.010\n",
            "Epoch 094 | train_loss = 1.0291 | val_node_acc = 0.565 | val_edge_violation = 0.111 | val_gnn_valid = 0.010\n",
            "Epoch 095 | train_loss = 1.0217 | val_node_acc = 0.560 | val_edge_violation = 0.117 | val_gnn_valid = 0.010\n",
            "Epoch 096 | train_loss = 1.0260 | val_node_acc = 0.562 | val_edge_violation = 0.129 | val_gnn_valid = 0.010\n",
            "Epoch 097 | train_loss = 1.0225 | val_node_acc = 0.561 | val_edge_violation = 0.162 | val_gnn_valid = 0.005\n",
            "Epoch 098 | train_loss = 1.0204 | val_node_acc = 0.564 | val_edge_violation = 0.107 | val_gnn_valid = 0.000\n",
            "Epoch 099 | train_loss = 1.0230 | val_node_acc = 0.567 | val_edge_violation = 0.120 | val_gnn_valid = 0.010\n",
            "Epoch 100 | train_loss = 1.0262 | val_node_acc = 0.564 | val_edge_violation = 0.106 | val_gnn_valid = 0.005\n",
            "Epoch 101 | train_loss = 1.0140 | val_node_acc = 0.567 | val_edge_violation = 0.102 | val_gnn_valid = 0.005\n",
            "Epoch 102 | train_loss = 1.0188 | val_node_acc = 0.554 | val_edge_violation = 0.121 | val_gnn_valid = 0.005\n",
            "Epoch 103 | train_loss = 1.0227 | val_node_acc = 0.562 | val_edge_violation = 0.113 | val_gnn_valid = 0.005\n",
            "Epoch 104 | train_loss = 1.0311 | val_node_acc = 0.557 | val_edge_violation = 0.123 | val_gnn_valid = 0.005\n",
            "Epoch 105 | train_loss = 1.0240 | val_node_acc = 0.564 | val_edge_violation = 0.098 | val_gnn_valid = 0.015\n",
            "Epoch 106 | train_loss = 1.0299 | val_node_acc = 0.544 | val_edge_violation = 0.140 | val_gnn_valid = 0.010\n",
            "Epoch 107 | train_loss = 1.0247 | val_node_acc = 0.561 | val_edge_violation = 0.123 | val_gnn_valid = 0.005\n",
            "Epoch 108 | train_loss = 1.0278 | val_node_acc = 0.553 | val_edge_violation = 0.091 | val_gnn_valid = 0.000\n",
            "Epoch 109 | train_loss = 1.0232 | val_node_acc = 0.559 | val_edge_violation = 0.171 | val_gnn_valid = 0.000\n",
            "Epoch 110 | train_loss = 1.0191 | val_node_acc = 0.575 | val_edge_violation = 0.101 | val_gnn_valid = 0.000\n",
            "Epoch 111 | train_loss = 1.0205 | val_node_acc = 0.551 | val_edge_violation = 0.118 | val_gnn_valid = 0.010\n",
            "Epoch 112 | train_loss = 1.0227 | val_node_acc = 0.567 | val_edge_violation = 0.118 | val_gnn_valid = 0.015\n",
            "Epoch 113 | train_loss = 1.0226 | val_node_acc = 0.554 | val_edge_violation = 0.111 | val_gnn_valid = 0.010\n",
            "Epoch 114 | train_loss = 1.0228 | val_node_acc = 0.504 | val_edge_violation = 0.253 | val_gnn_valid = 0.000\n",
            "Epoch 115 | train_loss = 1.0293 | val_node_acc = 0.563 | val_edge_violation = 0.132 | val_gnn_valid = 0.010\n",
            "Epoch 116 | train_loss = 1.0196 | val_node_acc = 0.554 | val_edge_violation = 0.129 | val_gnn_valid = 0.005\n",
            "Epoch 117 | train_loss = 1.0099 | val_node_acc = 0.564 | val_edge_violation = 0.118 | val_gnn_valid = 0.000\n",
            "Epoch 118 | train_loss = 1.0203 | val_node_acc = 0.567 | val_edge_violation = 0.115 | val_gnn_valid = 0.000\n",
            "Epoch 119 | train_loss = 1.0256 | val_node_acc = 0.567 | val_edge_violation = 0.138 | val_gnn_valid = 0.000\n",
            "Epoch 120 | train_loss = 1.0143 | val_node_acc = 0.565 | val_edge_violation = 0.112 | val_gnn_valid = 0.000\n",
            "Early stopping at epoch 120, best val_node_acc = 0.577\n",
            "Loaded best validation checkpoint.\n",
            "\n",
            "=== GNN-only test metrics ===\n",
            "node_acc: 0.5190\n",
            "graph_exact: 0.0000\n",
            "edge_violation: 0.1362\n",
            "gnn_valid_colorings: 0.0100\n",
            "\n",
            "=== Solver performance on test set (with/without GNN) ===\n",
            "\n",
            "Method: random\n",
            "  success_rate: 0.950\n",
            "  avg_backtracks: 792.550\n",
            "  avg_steps: 3204.975\n",
            "  avg_runtime_sec: 0.004309\n",
            "\n",
            "Method: degree\n",
            "  success_rate: 1.000\n",
            "  avg_backtracks: 26.075\n",
            "  avg_steps: 143.640\n",
            "  avg_runtime_sec: 0.000261\n",
            "\n",
            "Method: gnn_ordering\n",
            "  success_rate: 0.965\n",
            "  avg_backtracks: 405.655\n",
            "  avg_steps: 1644.640\n",
            "  avg_runtime_sec: 0.002807\n",
            "\n",
            "Method: gnn_warm_start\n",
            "  success_rate: 1.000\n",
            "  avg_backtracks: 19.890\n",
            "  avg_steps: 104.010\n",
            "  avg_runtime_sec: 0.000261\n",
            "\n",
            "Method: gnn_both\n",
            "  success_rate: 0.965\n",
            "  avg_backtracks: 405.655\n",
            "  avg_steps: 1644.640\n",
            "  avg_runtime_sec: 0.002594\n"
          ]
        }
      ]
    }
  ]
}